{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCjZ4E05n2myolDqP3MoZc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bommireddypally/Miniprojects/blob/main/01-retail-sales-analysis/retail_sales_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46b2650c"
      },
      "source": [
        "# Task\n",
        "List the contents of the `/kaggle/input/superstore-dataset-final` directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa326507"
      },
      "source": [
        "## Identify CSV File\n",
        "\n",
        "### Subtask:\n",
        "List the contents of the `/kaggle/input/superstore-dataset-final` directory to find the actual CSV file within it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4d60368"
      },
      "source": [
        "**Reasoning**:\n",
        "To identify the CSV file within the directory, I need to list its contents using a shell command.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e17559f0",
        "outputId": "47691557-3f08-4cf3-c26f-538e3c385e76"
      },
      "source": [
        "!ls /kaggle/input/superstore-dataset-final"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Sample - Superstore.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f96c4b1"
      },
      "source": [
        "## Load Data with Correct Path\n",
        "\n",
        "### Subtask:\n",
        "Modify the `pd.read_csv` call in cell `jTUmhf84vHjy` to use the full path to the CSV file found in the previous step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6ce8cdf"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step identified 'Sample - Superstore.csv' as the correct file within the dataset directory. This step modifies the `pd.read_csv` call to use this full, correct path to load the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c2827f6"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to load the CSV failed with a `UnicodeDecodeError`, indicating that the file is not encoded in 'utf-8'. I will try loading it with 'latin1' encoding, which is a common encoding for such issues.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c14cb67d",
        "outputId": "d1f6588d-ccec-491d-88f9-5a40c83efdd2"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Set style for better-looking plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# ============================================\n",
        "# STEP 1: LOAD THE DATA\n",
        "# ============================================\n",
        "# Download a sales dataset from Kaggle (e.g., Superstore Sales)\n",
        "# Place the CSV file in the same folder as this notebook\n",
        "\n",
        "# Load your data here\n",
        "df = pd.read_csv('/kaggle/input/superstore-dataset-final/Sample - Superstore.csv', encoding='latin1')\n",
        "\n",
        "print(\"Dataset loaded successfully!\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# ============================================\n",
        "# STEP 2: EXPLORE THE DATA\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"DATA EXPLORATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Basic info about the dataset\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "# Statistical summary\n",
        "print(\"\\nStatistical Summary:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Check column names\n",
        "print(\"\\nColumn Names:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# ============================================\n",
        "# STEP 3: DATA CLEANING\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"DATA CLEANING\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Remove duplicates\n",
        "df = df.drop_duplicates()\n",
        "print(f\"Duplicates removed. New shape: {df.shape}\")\n",
        "\n",
        "# Handle missing values (example - adjust based on your data)\n",
        "# df = df.dropna()  # or df.fillna(method='ffill')\n",
        "\n",
        "# Convert date columns to datetime (adjust column name as needed)\n",
        "# Example: if you have 'Order Date' column\n",
        "df['Order Date'] = pd.to_datetime(df['Order Date'])\n",
        "df['Ship Date'] = pd.to_datetime(df['Ship Date'])\n",
        "\n",
        "# Extract useful date features\n",
        "df['Order Year'] = df['Order Date'].dt.year\n",
        "df['Order Month'] = df['Order Date'].dt.month\n",
        "df['Order Month Name'] = df['Order Date'].dt.month_name()\n",
        "df['Order Day'] = df['Order Date'].dt.day\n",
        "df['Order Day of Week'] = df['Order Date'].dt.dayofweek # Monday=0, Sunday=6\n",
        "\n",
        "# Verify data types after conversion\n",
        "print(\"\\nDataset Info after Date Conversion:\")\n",
        "print(df.info())\n",
        "\n",
        "# ============================================\n",
        "# STEP 4: EXPLORATORY DATA ANALYSIS (EDA)\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"EXPLORATORY DATA ANALYSIS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Example analyses - adjust column names to match your dataset\n",
        "\n",
        "# 1. Total Sales and Profit\n",
        "print(f\"\\nTotal Sales: ${df['Sales'].sum():,.2f}\")\n",
        "print(f\"Total Profit: ${df['Profit'].sum():,.2f}\")\n",
        "print(f\"Average Order Value: ${df['Sales'].mean():,.2f}\")\n",
        "\n",
        "# 2. Sales by Category\n",
        "category_sales = df.groupby('Category')['Sales'].sum().sort_values(ascending=False)\n",
        "print(\"\\nSales by Category:\")\n",
        "print(category_sales)\n",
        "\n",
        "# 3. Top 10 Products by Sales\n",
        "# top_products = df.groupby('Product Name')['Sales'].sum().sort_values(ascending=False).head(10)\n",
        "# print(\"\\nTop 10 Products:\")\n",
        "# print(top_products)\n",
        "\n",
        "# ============================================\n",
        "# STEP 5: VISUALIZATIONS\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CREATING VISUALIZATIONS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Visualization 1: Sales Trend Over Time\n",
        "# monthly_sales = df.groupby('Month Name')['Sales'].sum()\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# monthly_sales.plot(kind='line', marker='o', color='blue', linewidth=2)\n",
        "# plt.title('Monthly Sales Trend', fontsize=16, fontweight='bold')\n",
        "# plt.xlabel('Month', fontsize=12)\n",
        "# plt.ylabel('Total Sales ($)', fontsize=12)\n",
        "# plt.xticks(rotation=45)\n",
        "# plt.grid(True, alpha=0.3)\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "# Visualization 2: Sales by Category (Bar Chart)\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# category_sales.plot(kind='bar', color='skyblue', edgecolor='black')\n",
        "# plt.title('Sales by Category', fontsize=16, fontweight='bold')\n",
        "# plt.xlabel('Category', fontsize=12)\n",
        "# plt.ylabel('Total Sales ($)', fontsize=12)\n",
        "# plt.xticks(rotation=45)\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "# Visualization 3: Top 10 Products (Horizontal Bar)\n",
        "# plt.figure(figsize=(10, 8))\n",
        "# top_products.plot(kind='barh', color='coral', edgecolor='black')\n",
        "# plt.title('Top 10 Products by Sales', fontsize=16, fontweight='bold')\n",
        "# plt.xlabel('Total Sales ($)', fontsize=12)\n",
        "# plt.ylabel('Product', fontsize=12)\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "# Visualization 4: Sales Distribution by Region (Pie Chart)\n",
        "# region_sales = df.groupby('Region')['Sales'].sum()\n",
        "# plt.figure(figsize=(8, 8))\n",
        "# plt.pie(region_sales, labels=region_sales.index, autopct='%1.1f%%', startangle=90)\n",
        "# plt.title('Sales Distribution by Region', fontsize=16, fontweight='bold')\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "# ============================================\n",
        "# STEP 6: KEY INSIGHTS\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"KEY INSIGHTS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Write your findings here after analyzing the data\n",
        "insights = \"\"\"\n",
        "Based on the analysis, here are the key findings:\n",
        "\n",
        "1. [Your insight about sales trends]\n",
        "2. [Your insight about top-performing categories/products]\n",
        "3. [Your insight about regional performance]\n",
        "4. [Your insight about seasonal patterns]\n",
        "5. [Your insight about profitability]\n",
        "\n",
        "Recommendations:\n",
        "- [Actionable recommendation based on your findings]\n",
        "- [Another recommendation]\n",
        "\"\"\"\n",
        "\n",
        "print(insights)\n",
        "\n",
        "# ============================================\n",
        "# BONUS: ADVANCED ANALYSIS (Optional)\n",
        "# ============================================\n",
        "\n",
        "# Calculate profit margin by category\n",
        "# df['Profit Margin'] = (df['Profit'] / df['Sales']) * 100\n",
        "# margin_by_category = df.groupby('Category')['Profit Margin'].mean()\n",
        "# print(\"\\nProfit Margin by Category:\")\n",
        "# print(margin_by_category)\n",
        "\n",
        "# Correlation analysis\n",
        "# numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "# correlation = df[numeric_cols].corr()\n",
        "# plt.figure(figsize=(10, 8))\n",
        "# sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0)\n",
        "# plt.title('Correlation Heatmap', fontsize=16, fontweight='bold')\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Analysis Complete! ✨\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Uncomment and adjust the code sections based on your dataset columns\")\n",
        "print(\"2. Run each section step by step\")\n",
        "print(\"3. Document your findings in the insights section\")\n",
        "print(\"4. Save your visualizations\")\n",
        "print(\"5. Create a README.md for your GitHub repository\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully!\n",
            "Shape: (9994, 21)\n",
            "\n",
            "First few rows:\n",
            "   Row ID        Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
            "0       1  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
            "1       2  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
            "2       3  CA-2016-138688   6/12/2016   6/16/2016    Second Class    DV-13045   \n",
            "3       4  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
            "4       5  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
            "\n",
            "     Customer Name    Segment        Country             City  ...  \\\n",
            "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
            "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
            "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
            "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
            "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
            "\n",
            "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
            "0       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
            "1       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
            "2       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
            "3       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
            "4       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
            "\n",
            "                                        Product Name     Sales  Quantity  \\\n",
            "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
            "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
            "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
            "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
            "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
            "\n",
            "   Discount    Profit  \n",
            "0      0.00   41.9136  \n",
            "1      0.00  219.5820  \n",
            "2      0.00    6.8714  \n",
            "3      0.45 -383.0310  \n",
            "4      0.20    2.5164  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "\n",
            "==================================================\n",
            "DATA EXPLORATION\n",
            "==================================================\n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9994 entries, 0 to 9993\n",
            "Data columns (total 21 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Row ID         9994 non-null   int64  \n",
            " 1   Order ID       9994 non-null   object \n",
            " 2   Order Date     9994 non-null   object \n",
            " 3   Ship Date      9994 non-null   object \n",
            " 4   Ship Mode      9994 non-null   object \n",
            " 5   Customer ID    9994 non-null   object \n",
            " 6   Customer Name  9994 non-null   object \n",
            " 7   Segment        9994 non-null   object \n",
            " 8   Country        9994 non-null   object \n",
            " 9   City           9994 non-null   object \n",
            " 10  State          9994 non-null   object \n",
            " 11  Postal Code    9994 non-null   int64  \n",
            " 12  Region         9994 non-null   object \n",
            " 13  Product ID     9994 non-null   object \n",
            " 14  Category       9994 non-null   object \n",
            " 15  Sub-Category   9994 non-null   object \n",
            " 16  Product Name   9994 non-null   object \n",
            " 17  Sales          9994 non-null   float64\n",
            " 18  Quantity       9994 non-null   int64  \n",
            " 19  Discount       9994 non-null   float64\n",
            " 20  Profit         9994 non-null   float64\n",
            "dtypes: float64(3), int64(3), object(15)\n",
            "memory usage: 1.6+ MB\n",
            "None\n",
            "\n",
            "Statistical Summary:\n",
            "            Row ID   Postal Code         Sales     Quantity     Discount  \\\n",
            "count  9994.000000   9994.000000   9994.000000  9994.000000  9994.000000   \n",
            "mean   4997.500000  55190.379428    229.858001     3.789574     0.156203   \n",
            "std    2885.163629  32063.693350    623.245101     2.225110     0.206452   \n",
            "min       1.000000   1040.000000      0.444000     1.000000     0.000000   \n",
            "25%    2499.250000  23223.000000     17.280000     2.000000     0.000000   \n",
            "50%    4997.500000  56430.500000     54.490000     3.000000     0.200000   \n",
            "75%    7495.750000  90008.000000    209.940000     5.000000     0.200000   \n",
            "max    9994.000000  99301.000000  22638.480000    14.000000     0.800000   \n",
            "\n",
            "            Profit  \n",
            "count  9994.000000  \n",
            "mean     28.656896  \n",
            "std     234.260108  \n",
            "min   -6599.978000  \n",
            "25%       1.728750  \n",
            "50%       8.666500  \n",
            "75%      29.364000  \n",
            "max    8399.976000  \n",
            "\n",
            "Missing Values:\n",
            "Row ID           0\n",
            "Order ID         0\n",
            "Order Date       0\n",
            "Ship Date        0\n",
            "Ship Mode        0\n",
            "Customer ID      0\n",
            "Customer Name    0\n",
            "Segment          0\n",
            "Country          0\n",
            "City             0\n",
            "State            0\n",
            "Postal Code      0\n",
            "Region           0\n",
            "Product ID       0\n",
            "Category         0\n",
            "Sub-Category     0\n",
            "Product Name     0\n",
            "Sales            0\n",
            "Quantity         0\n",
            "Discount         0\n",
            "Profit           0\n",
            "dtype: int64\n",
            "\n",
            "Column Names:\n",
            "['Row ID', 'Order ID', 'Order Date', 'Ship Date', 'Ship Mode', 'Customer ID', 'Customer Name', 'Segment', 'Country', 'City', 'State', 'Postal Code', 'Region', 'Product ID', 'Category', 'Sub-Category', 'Product Name', 'Sales', 'Quantity', 'Discount', 'Profit']\n",
            "\n",
            "==================================================\n",
            "DATA CLEANING\n",
            "==================================================\n",
            "Duplicates removed. New shape: (9994, 21)\n",
            "\n",
            "==================================================\n",
            "EXPLORATORY DATA ANALYSIS\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "CREATING VISUALIZATIONS\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "KEY INSIGHTS\n",
            "==================================================\n",
            "\n",
            "Based on the analysis, here are the key findings:\n",
            "\n",
            "1. [Your insight about sales trends]\n",
            "2. [Your insight about top-performing categories/products]\n",
            "3. [Your insight about regional performance]\n",
            "4. [Your insight about seasonal patterns]\n",
            "5. [Your insight about profitability]\n",
            "\n",
            "Recommendations:\n",
            "- [Actionable recommendation based on your findings]\n",
            "- [Another recommendation]\n",
            "\n",
            "\n",
            "==================================================\n",
            "Analysis Complete! ✨\n",
            "==================================================\n",
            "\n",
            "Next steps:\n",
            "1. Uncomment and adjust the code sections based on your dataset columns\n",
            "2. Run each section step by step\n",
            "3. Document your findings in the insights section\n",
            "4. Save your visualizations\n",
            "5. Create a README.md for your GitHub repository\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbf3532b"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Confirm that the dataset is loaded successfully and display the first few rows to verify.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "170141dc"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The correct CSV file, `Sample - Superstore.csv`, was successfully identified within the `/kaggle/input/superstore-dataset-final` directory.\n",
        "*   The dataset was successfully loaded using `pd.read_csv` by specifying `encoding='latin1'`, which resolved an initial `UnicodeDecodeError`.\n",
        "*   The loaded dataset `df` contains 9,994 rows and 21 columns.\n",
        "*   Initial data quality checks revealed no missing values and no duplicate rows after an attempt to remove them, confirming the dataset is relatively clean for further analysis.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Always verify the correct file path and consider different encoding options (like 'latin1') when encountering `UnicodeDecodeError` during CSV loading.\n",
        "*   With the data successfully loaded and basic cleaning confirmed, the next logical steps involve performing detailed Exploratory Data Analysis (EDA) and creating visualizations to uncover trends and patterns in the Superstore sales data.\n"
      ]
    }
  ]
}